{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is extremely RAM-intensive, and quickly consumes all my memory in laptop as well as Google Colab causing the kernels to crash repeatedly. Due to hardware constraints, I have prepared a small dataset- of 1000 offensive and non-offensive texts along with their descriptions. They are the first 1000 (non offensive) and the last 1000 (offensive) values from the caption_description dataframe prepared earlier. The following document involves a sample code which was used to make the dataset, but it will not run without crashing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>file</th>\n",
       "      <th>description</th>\n",
       "      <th>sets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>berserk 2016 is a good adaptation you're kidd...</td>\n",
       "      <td>71094.png</td>\n",
       "      <td>woman with a monkey mask and a fake monkey</td>\n",
       "      <td>[test_unseen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>my life goal? make somebody this fucking trig...</td>\n",
       "      <td>91724.png</td>\n",
       "      <td>woman holding a cigarette in her hand</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\" i don't wanna, just get it, get it, get it, ...</td>\n",
       "      <td>64280.png</td>\n",
       "      <td>man wearing a hat and a tie</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"1st day of 4th grade sandy hook elementary sc...</td>\n",
       "      <td>67082.png</td>\n",
       "      <td>group of children standing in front of a schoo...</td>\n",
       "      <td>[dev_seen, dev_unseen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"a blow job a day will keep his side chicks aw...</td>\n",
       "      <td>46380.png</td>\n",
       "      <td>woman with a black top and a blue background</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12135</th>\n",
       "      <td>1</td>\n",
       "      <td>your post is under coon review and it ain't lo...</td>\n",
       "      <td>59482.png</td>\n",
       "      <td>man speaking into a microphone</td>\n",
       "      <td>[test_unseen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>1</td>\n",
       "      <td>your purchase of $19.99 comes to $21.36 after ...</td>\n",
       "      <td>21693.png</td>\n",
       "      <td>man in a kitchen with a calculator</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12137</th>\n",
       "      <td>1</td>\n",
       "      <td>your purchase of $19.99 comes to $21.36 after ...</td>\n",
       "      <td>59837.png</td>\n",
       "      <td>man in a kitchen with a calculator</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12138</th>\n",
       "      <td>1</td>\n",
       "      <td>your sense of humor is so dark, police want to...</td>\n",
       "      <td>42897.png</td>\n",
       "      <td>man talking into a microphone</td>\n",
       "      <td>[train]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12139</th>\n",
       "      <td>1</td>\n",
       "      <td>your view on the refugees? me: flir 1340</td>\n",
       "      <td>57846.png</td>\n",
       "      <td>crowd of people walking down a street</td>\n",
       "      <td>[test_unseen]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12140 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text       file  \\\n",
       "0          0   berserk 2016 is a good adaptation you're kidd...  71094.png   \n",
       "1          0   my life goal? make somebody this fucking trig...  91724.png   \n",
       "2          0  \" i don't wanna, just get it, get it, get it, ...  64280.png   \n",
       "3          0  \"1st day of 4th grade sandy hook elementary sc...  67082.png   \n",
       "4          0  \"a blow job a day will keep his side chicks aw...  46380.png   \n",
       "...      ...                                                ...        ...   \n",
       "12135      1  your post is under coon review and it ain't lo...  59482.png   \n",
       "12136      1  your purchase of $19.99 comes to $21.36 after ...  21693.png   \n",
       "12137      1  your purchase of $19.99 comes to $21.36 after ...  59837.png   \n",
       "12138      1  your sense of humor is so dark, police want to...  42897.png   \n",
       "12139      1           your view on the refugees? me: flir 1340  57846.png   \n",
       "\n",
       "                                             description  \\\n",
       "0             woman with a monkey mask and a fake monkey   \n",
       "1                  woman holding a cigarette in her hand   \n",
       "2                            man wearing a hat and a tie   \n",
       "3      group of children standing in front of a schoo...   \n",
       "4           woman with a black top and a blue background   \n",
       "...                                                  ...   \n",
       "12135                     man speaking into a microphone   \n",
       "12136                 man in a kitchen with a calculator   \n",
       "12137                 man in a kitchen with a calculator   \n",
       "12138                      man talking into a microphone   \n",
       "12139              crowd of people walking down a street   \n",
       "\n",
       "                         sets  \n",
       "0               [test_unseen]  \n",
       "1                     [train]  \n",
       "2                     [train]  \n",
       "3      [dev_seen, dev_unseen]  \n",
       "4                     [train]  \n",
       "...                       ...  \n",
       "12135           [test_unseen]  \n",
       "12136                 [train]  \n",
       "12137                 [train]  \n",
       "12138                 [train]  \n",
       "12139           [test_unseen]  \n",
       "\n",
       "[12140 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df= pd.read_pickle(\"../outputs/caption_description.pkl\")\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= main_df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(tokenizer.tokenize(sentence)) for sentence in main_df[\"text\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals=[]\n",
    "attention_masks=[]\n",
    "for sentence in text:\n",
    "    vals.append(['[CLS]']+tokenizer.tokenize(sentence)+['[SEP]'])\n",
    "max_pad= max([len(val) for val in vals])\n",
    "\n",
    "for val in vals:\n",
    "    pad_count= max_pad-len(val)\n",
    "    attention_masks.append([1]*len(val)+[0]*pad_count)\n",
    "    if(len(val)!=max_pad):\n",
    "        val.extend(['[PAD]']*pad_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids=[]\n",
    "for val in vals:\n",
    "    token_ids.append(tokenizer.convert_tokens_to_ids(val))\n",
    "token_ids= torch.tensor(token_ids)\n",
    "attention_masks= torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = len(token_ids) // batch_size\n",
    "if len(token_ids) % batch_size != 0:\n",
    "    num_batches += 1\n",
    "sentence_embeddings=[]\n",
    "\n",
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(num_batches):\n",
    "#     start_index = i * batch_size\n",
    "#     end_index = min((i + 1) * batch_size, len(token_ids))\n",
    "\n",
    "#     # Extract a batch of token IDs and attention masks\n",
    "#     token_ids_batch = token_ids[start_index:end_index]\n",
    "#     attention_masks_batch = attention_masks[start_index:end_index]\n",
    "\n",
    "#     # Convert to tensors\n",
    "#     token_ids_tensor = torch.tensor(token_ids_batch)\n",
    "#     attention_masks_tensor = torch.tensor(attention_masks_batch)\n",
    "\n",
    "#     # Forward pass through BERT model\n",
    "#     output = model(token_ids_tensor, attention_mask=attention_masks_tensor)\n",
    "#     sentence_embeddings.append(output[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
